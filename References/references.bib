
@inproceedings{seznec_analysis_2005,
	title = {Analysis of the {O}-{GEometric} history length branch predictor},
	doi = {10.1109/ISCA.2005.13},
	abstract = {In this paper, we introduce and analyze the Optimized GEometric History Length (O-GEHL) branch Predictor that efficiently exploits very long global histories in the 100-200 bits range. The GEHL predictor features several predictor tables T(i) (e.g. 8) indexed through independent functions of the global branch history and branch address. The set of used global history lengths forms a geometric series, i.e., L(j) = /spl alpha//sup j-1/L(1). This allows the GEHL predictor to efficiently capture correlation on recent branch outcomes as well as on very old branches. As on perceptron predictors, the prediction is computed through the addition of the predictions read on the predictor tables. The O-GEHL predictor further improves the ability of the GEHL predictor to exploit very long histories through the addition of dynamic history fitting and dynamic threshold fitting. The O-GEHL predictor can be ahead pipelined to provide in time predictions on every cycle.},
	booktitle = {32nd {International} {Symposium} on {Computer} {Architecture} ({ISCA}'05)},
	author = {Seznec, A.},
	month = jun,
	year = {2005},
	note = {ISSN: 1063-6897},
	keywords = {Accuracy, Application software, Best practices, Computer architecture, Counting circuits, Fitting, History, Performance gain, Pipelines, Space exploration},
	pages = {394--405},
}

@article{jimenez_multiperspective_2016,
	title = {Multiperspective {Perceptron} {Predictor}},
	url = {https://jilp.org/cbp2016/},
	language = {en},
	journal = {Proceedings of the 5th Championship on Branch Prediction},
	author = {Jimenez, Daniel A},
	year = {2016},
	keywords = {CBP-5, DanielJimenez1},
	pages = {4},
}

@article{jimenez_multiperspective_2016-1,
	title = {Multiperspective {Perceptron} {Predictor} with {TAGE}},
	url = {https://jilp.org/cbp2016/},
	abstract = {I present a branch predictor based on the idea of viewing branch history from multiple perspectives, combining perceptron-based prediction and TAGE. A hashed perceptron predictor uses previous outcomes and addresses of branches organized in ways beyond the traditional global and local history. This multiperspective perceptron predictor with TAGE achieves a mean mispredictions per 1000 instruction (MPKI) rate of 5.226 given an 8.25KB hardware budget, 4.048 for a 64.25KB hardware budget, and 2.967 for an unlimited hardware budget.},
	language = {en},
	journal = {Proceedings of the 5th Championship on Branch Prediction},
	author = {Jimenez, Daniel A},
	year = {2016},
	keywords = {CBP-5, DanielJimenez2},
	pages = {4},
}

@article{pruett_dynamically_2016,
	title = {Dynamically {Sizing} the {TAGE} {Branch} {Predictor}},
	url = {https://jilp.org/cbp2016/},
	abstract = {The statically assigned size of each table in TAGE limits the branch predictor accuracy for many benchmarks. We provide a mechanism for allocating TAGE table sizes at run time, based on the needs of the individual benchmark. The resulting dynamically reconﬁgurable TAGE branch predictor results in an MPKI of 5.370 (8KB budget) and 4.265 (64KB budget).},
	language = {en},
	journal = {Proceedings of the 5th Championship on Branch Prediction},
	author = {Pruett, Stephen and Zangeneh, Siavash and Fakhrzadehgan, Ali and Lin, Ben and Patt, Yale N},
	year = {2016},
	pages = {5},
}

@article{seznec_exploring_2016,
	title = {Exploring branch predictability limits with the {MTAGE}+{SC} predictor},
	url = {https://jilp.org/cbp2016/},
	language = {en},
	journal = {Proceedings of the 5th Championship on Branch Prediction},
	author = {Seznec, Andre},
	year = {2016},
	keywords = {AndreSeznecUnlimited, CBP-5},
	pages = {4},
}

@article{seznec_case_2006,
	title = {A {Case} for (partially) {Tagged} {Geometric} {History} {Length} {Branch} {Prediction}},
	volume = {8},
	abstract = {It is now widely admitted that in order to provide state-of-the-art accuracy, a conditional branch predictor must combine several predictions. Recent research has shown that an adder tree is a very effective approach for the prediction combination function. In this paper, we present a more cost effective solution for this prediction combination function for predictors relying on several predictor components indexed with different history lengths. Using geometric history length as the O-GEHL predictor, the TAGE predictor uses (partially) tagged components as the PPM-like predictor. TAGE relies on (partial) hit-miss detection as the prediction computation function. TAGE provides state-of-the-art prediction accuracy on conditional branches. In particular, at equivalent storage budgets, the TAGE predictor significantly outperforms all the predictors that were presented at the Championship Branch Prediction in december 2004. The accuracy of the prediction of the targets of indirect branches is a major issue on some applications. We show that the principles of the TAGE predictor can be directly applied to the prediction of indirect branches. The ITTAGE predictor (Indirect Target TAgged GEometric history length) significantly outperforms previous state-of-the-art indirect target branch predictors. Both TAGE and ITTAGE predictors feature tagged predictor components indexed with distinct history lengths forming a geometric series. They can be associated in a single cost-effective predictor, sharing tables and predictor logic, the COTTAGE predictor (COnditional and indirect Target TAgged GEometric history length).},
	language = {en},
	urldate = {2022-07-12},
	journal = {The Journal of Instruction-Level Parallelism},
	author = {Seznec, André and Michaud, Pierre},
	month = feb,
	year = {2006},
	keywords = {key},
	pages = {23},
}

@article{seznec_tage-sc-l_2016,
	title = {{TAGE}-{SC}-{L} {Branch} {Predictors} {Again}},
	url = {https://jilp.org/cbp2016/},
	language = {en},
	journal = {Proceedings of the 5th Championship on Branch Prediction},
	author = {Seznec, Andre},
	year = {2016},
	keywords = {AndreSeznecLimited, CBP-5},
}

@inproceedings{gupta_rebooting_2021,
	title = {Rebooting {Virtual} {Memory} with {Midgard}},
	doi = {10.1109/ISCA52012.2021.00047},
	abstract = {Computer systems designers are building cache hierarchies with higher capacity to capture the ever-increasing working sets of modern workloads. Cache hierarchies with higher capacity improve system performance but shift the performance bottleneck to address translation. We propose Midgard, an intermediate address space between the virtual and the physical address spaces, to mitigate address translation overheads without program-level changes.Midgard leverages the operating system concept of virtual memory areas (VMAs) to realize a single Midgard address space where VMAs of all processes can be uniquely mapped. The Midgard address space serves as the namespace for all data in a coherence domain and the cache hierarchy. Because real-world workloads use far fewer VMAs than pages to represent their virtual address space, virtual to Midgard translation is achieved with hardware structures that are much smaller than TLB hierarchies. Costlier Midgard to physical address translations are needed only on LLC misses, which become much less frequent with larger caches. As a consequence, Midgard shows that instead of amplifying address translation overheads, memory hierarchies with large caches can reduce address translation overheads.Our evaluation shows that Midgard achieves only 5\% higher address translation overhead as compared to traditional TLB hierarchies for 4KB pages when using a 16MB aggregate LLC. Midgard also breaks even with traditional TLB hierarchies for 2MB pages when using a 256MB aggregate LLC. For cache hierarchies with higher capacity, Midgard’s address translation overhead drops to near zero as secondary and tertiary data working sets fit in the LLC, while traditional TLBs suffer even higher degrees of address translation overhead.},
	booktitle = {2021 {ACM}/{IEEE} 48th {Annual} {International} {Symposium} on {Computer} {Architecture} ({ISCA})},
	author = {Gupta, Siddharth and Bhattacharyya, Atri and Oh, Yunho and Bhattacharjee, Abhishek and Falsafi, Babak and Payer, Mathias},
	month = jun,
	year = {2021},
	note = {ISSN: 2575-713X},
	keywords = {Access control, Aggregates, Buildings, Filtering, Operating systems, Prototypes, System performance, address translation, datacenters, memory hierarchy, servers, virtual caches, virtual memory},
	pages = {512--525},
}

@inproceedings{zangeneh_branchnet_2020,
	title = {{BranchNet}: {A} {Convolutional} {Neural} {Network} to {Predict} {Hard}-{To}-{Predict} {Branches}},
	shorttitle = {{BranchNet}},
	doi = {10.1109/MICRO50266.2020.00022},
	abstract = {The state-of-the-art branch predictor, TAGE, remains inefficient at identifying correlated branches deep in a noisy global branch history. We argue this inefficiency is a fundamental limitation of runtime branch prediction and not a coincidental artifact due to the design of TAGE. To further improve branch prediction, we need to relax the constraint of runtime only training and adopt more sophisticated prediction mechanisms. To this end, Tarsa et al. proposed using convolutional neural networks (CNNs) that are trained at compile-time to accurately predict branches that TAGE cannot. Given enough profiling coverage, CNNs learn input-independent branch correlations that can accurately predict branches when running a program with unseen inputs. We build on their work and introduce BranchNet, a CNN with a practical on-chip inference engine tailored to the needs of branch prediction. At runtime, BranchNet predicts a few hard-to-predict branches, while TAGE-SC-L predicts the remaining branches. This hybrid approach reduces the MPKI of SPEC2017 Integer benchmarks by 7.6\% (and up to 15.7\%) when compared to a very large (impractical) MTAGE-SC baseline, demonstrating a fundamental advantage in the prediction capabilities of BranchNet compared to TAGE-like predictors. We also propose a practical resource-constrained variant of BranchNet that improves the MPKI by 9.6\% (and up to 17.7\%) compared to a 64KB TAGE-SC-L without increasing the prediction latency.},
	booktitle = {2020 53rd {Annual} {IEEE}/{ACM} {International} {Symposium} on {Microarchitecture} ({MICRO})},
	author = {Zangeneh, Siavash and Pruett, Stephen and Lym, Sangkug and Patt, Yale N.},
	month = oct,
	year = {2020},
	keywords = {Hard-to-predict branches, Offline training},
	pages = {118--130},
}

@article{zhang_dynamic_2020,
	title = {A {Dynamic} {Branch} {Predictor} {Based} on {Parallel} {Structure} of {SRNN}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.2992643},
	abstract = {Branch predictor is a key component of processor, which can improve the efficiency of instruction execution. The branch predictor based on machine learning algorithm can achieve high branch prediction accuracy, but it has the disadvantages of long training time and high access delay. As a neural network algorithm, Recurrent Neural Network (RNN) is good at processing data related to time series, and can learn the correlation between data faster. Sliced Recurrent Neural Network (SRNN) parallelizes the RNN algorithm, effectively reducing the access delay of the RNN algorithm. In this paper, a dynamic branch predictor based on parallel structure of SRNN is proposed to accelerate the training time and reduces the computing delay. The optimal design parameters of predictor, which has prediction accuracy with lower source cost, are selected through a serial simulations. The experimental results show that the branch predictor proposed in this paper has higher prediction accuracy than the traditional Bimod and Gshare branch predictors under the same hardware consumption, and its branch prediction rate is 2.34\% higher than the traditional Perceptron neural predictor in the short learning period.},
	journal = {IEEE Access},
	author = {Zhang, Lei and Wu, Ning and Ge, Fen and Zhou, Fang and Yahya, Mahammad Rehan},
	year = {2020},
	keywords = {Branch predictor, Heuristic algorithms, Inference algorithms, Machine learning algorithms, Mathematical model, Prediction algorithms, Recurrent neural networks, Training, machine learning, recurrent neural network (RNN), sliced recurrent neural network (SRNN)},
	pages = {86230--86237},
}

@article{bartolucci_fusion-based_2021,
	title = {Fusion-based quantum computation},
	url = {https://arxiv.org/abs/2101.09310v1},
	doi = {10.48550/arXiv.2101.09310},
	abstract = {We introduce fusion-based quantum computing (FBQC) - a model of universal quantum computation in which entangling measurements, called fusions, are performed on the qubits of small constant-sized entangled resource states. We introduce a stabilizer formalism for analyzing fault tolerance and computation in these schemes. This framework naturally captures the error structure that arises in certain physical systems for quantum computing, such as photonics. FBQC can offer significant architectural simplifications, enabling hardware made up of many identical modules, requiring an extremely low depth of operations on each physical qubit and reducing classical processing requirements. We present two pedagogical examples of fault-tolerant schemes constructed in this framework and numerically evaluate their threshold under a hardware agnostic fusion error model including both erasure and Pauli error. We also study an error model of linear optical quantum computing with probabilistic fusion and photon loss. In FBQC the non-determinism of fusion is directly dealt with by the quantum error correction protocol, along with other errors. We find that tailoring the fault-tolerance framework to the physical system allows the scheme to have a higher threshold than schemes reported in literature. We present a ballistic scheme which can tolerate a 10.4\% probability of suffering photon loss in each fusion.},
	language = {en},
	urldate = {2022-08-04},
	author = {Bartolucci, Sara and Birchall, Patrick and Bombin, Hector and Cable, Hugo and Dawson, Chris and Gimeno-Segovia, Mercedes and Johnston, Eric and Kieling, Konrad and Nickerson, Naomi and Pant, Mihir and Pastawski, Fernando and Rudolph, Terry and Sparrow, Chris},
	month = jan,
	year = {2021},
}

@article{cohen_low-overhead_2022,
	title = {Low-overhead fault-tolerant quantum computing using long-range connectivity},
	volume = {8},
	url = {https://www.science.org/doi/full/10.1126/sciadv.abn1717},
	doi = {10.1126/sciadv.abn1717},
	number = {20},
	urldate = {2022-08-04},
	journal = {Science Advances},
	author = {Cohen, Lawrence Z. and Kim, Isaac H. and Bartlett, Stephen D. and Brown, Benjamin J.},
	month = may,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {eabn1717},
}

@article{andrijevic_cellular_2022,
	title = {Cellular recovery after prolonged warm ischaemia of the whole body},
	copyright = {2022 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-022-05016-1},
	doi = {10.1038/s41586-022-05016-1},
	abstract = {After cessation of blood flow or similar ischaemic exposures, deleterious molecular cascades commence in mammalian cells, eventually leading to their death1,2. Yet with targeted interventions, these processes can be mitigated or reversed, even minutes or hours post mortem, as also reported in the isolated porcine brain using BrainEx technology3. To date, translating single-organ interventions to intact, whole-body applications remains hampered by circulatory and multisystem physiological challenges. Here we describe OrganEx, an adaptation of the BrainEx extracorporeal pulsatile-perfusion system and cytoprotective perfusate for porcine whole-body settings. After 1 h of warm ischaemia, OrganEx application preserved tissue integrity, decreased cell death and restored selected molecular and cellular processes across multiple vital organs. Commensurately, single-nucleus transcriptomic analysis revealed organ- and cell-type-specific gene expression patterns that are reflective of specific molecular and cellular repair processes. Our analysis comprises a comprehensive resource of cell-type-specific changes during defined ischaemic intervals and perfusion interventions spanning multiple organs, and it reveals an underappreciated potential for cellular recovery after prolonged whole-body warm ischaemia in a large mammal.},
	language = {en},
	urldate = {2022-08-04},
	journal = {Nature},
	author = {Andrijevic, David and Vrselja, Zvonimir and Lysyy, Taras and Zhang, Shupei and Skarica, Mario and Spajic, Ana and Dellal, David and Thorn, Stephanie L. and Duckrow, Robert B. and Ma, Shaojie and Duy, Phan Q. and Isiktas, Atagun U. and Liang, Dan and Li, Mingfeng and Kim, Suel-Kee and Daniele, Stefano G. and Banu, Khadija and Perincheri, Sudhir and Menon, Madhav C. and Huttner, Anita and Sheth, Kevin N. and Gobeske, Kevin T. and Tietjen, Gregory T. and Zaveri, Hitten P. and Latham, Stephen R. and Sinusas, Albert J. and Sestan, Nenad},
	month = aug,
	year = {2022},
	note = {Publisher: Nature Publishing Group},
	keywords = {Medical research, Physiology},
	pages = {1--8},
}

@misc{noauthor_welink_nodate,
	title = {{WeLink} {Note} {\textbar} {No} {Title}},
	url = {http://wenote.huawei.com/wapp/folder/09363030-fba3-11ec-9b6e-395d1faffc2e?c=%2FSummaries%2F&docGuid=0d0d3040-0bf3-11ed-9f60-5720efc2053c},
	urldate = {2022-07-25},
}

@article{kulkarni_review_2022,
	title = {A {Review} of {Branch} {Prediction} {Schemes} and a {Study} of {Branch} {Predictors} in {Modern} {Microprocessors}},
	abstract = {Accurate branch prediction has become increasingly important as the trend continues to move towards superscalar and deeply pipelined processors. This has necessitated implementation of advanced branch handling techniques which have high prediction rates and low misprediction penalties. In this paper, apart from discussing some of the important branch prediction schemes like static, dynamic and hybrid prediction, we examine branch predictors in modern processors like Alpha 21264, Pentium 4, Itanium 2, ARM-11, Opteron and Power5. We present a systematic summary of our study, by emphasizing design tradeoffs and contrasting effectiveness of the different schemes.},
	author = {Kulkarni, Ketan and Mekala, Venkata},
	month = jul,
	year = {2022},
}

@misc{noauthor_championship_nodate,
	title = {Championship {Branch} {Prediction}},
	url = {https://jilp.org/cbp2016/},
	urldate = {2022-07-21},
}

@misc{noauthor_google_nodate,
	title = {Google {Workload} {Traces}},
	url = {https://dynamorio.org/google_workload_traces.html},
	urldate = {2022-07-21},
}

@article{mcfarling_combining_1993,
	title = {Combining {Branch} {Predictors}},
	language = {en},
	author = {McFarling, Scott},
	year = {1993},
	keywords = {gShare, key},
	pages = {22},
}

@article{michaud_ppm-like_2005,
	title = {A {PPM}-like, tag-based branch predictor},
	volume = {7},
	abstract = {This paper describes cbp1.5, the tag-based, global-history predictor derived from PPM that was rank five at the first Championship Branch Prediction competition. This predictor is a particular instance of a family of predictors which we call GPPM. We introduce GPPM-ideal, an ideal GPPM predictor. It is possible to derive cbp1.5 from GPPM-ideal by introducing a series of degradations corresponding to real-life constraints. We characterize cbp1.5 by quantifying the impact of each degradation on the distributed CBP traces.},
	journal = {Journal of Instruction-Level Parallelism},
	author = {Michaud, Pierre},
	month = apr,
	year = {2005},
	pages = {1--10},
}

@article{ishii_rebasing_2020,
	title = {Rebasing {Instruction} {Prefetching}: {An} {Industry} {Perspective}},
	volume = {19},
	issn = {1556-6064},
	shorttitle = {Rebasing {Instruction} {Prefetching}},
	doi = {10.1109/LCA.2020.3035068},
	abstract = {Instruction prefetching can play a pivotal role in improving the performance of workloads with large instruction footprints and frequent, costly frontend stalls. In particular, Fetch Directed Prefetching (FDP) is an effective technique to mitigate frontend stalls since it leverages existing branch prediction resources in a processor and incurs very little hardware overhead. Modern processors have been trending towards provisioning more frontend resources, and this bodes well for FDP as it requires these resources to be effective. However, recent academic research has been using outdated and less than optimal frontend baselines that employ smaller structures, which may result in misleading outcomes. In this letter, we present a detailed FDP microarchitecture and evaluate two improvements, better branch history management and post-fetch correction. We believe that our FDP-based frontend design can serve as a new reference baseline for instruction prefetching research to bridge the gap between academia and industry.},
	number = {2},
	journal = {IEEE Computer Architecture Letters},
	author = {Ishii, Yasuo and Lee, Jaekyu and Nathella, Krishnendra and Sunwoo, Dam},
	month = jul,
	year = {2020},
	note = {Conference Name: IEEE Computer Architecture Letters},
	keywords = {Hardware, History, Industries, Instruction prefetching, Microarchitecture, Prefetching, branch predictor},
	pages = {147--150},
}

@misc{frumusanu_apple_2022,
	title = {Apple {Announces} {The} {Apple} {Silicon} {M1}: {Ditching} x86 - {What} to {Expect}, {Based} on {A14}},
	shorttitle = {Apple {Announces} {The} {Apple} {Silicon} {M1}},
	url = {https://www.anandtech.com/show/16226/apple-silicon-m1-a14-deep-dive},
	author = {Frumusanu, Andrei},
	month = nov,
	year = {2022},
}

@misc{frumusanu_intel_2021,
	title = {Intel {Architecture} {Day} 2021: {Alder} {Lake}, {Golden} {Cove}, and {Gracemont} {Detailed}},
	shorttitle = {Intel {Architecture} {Day} 2021},
	url = {https://www.anandtech.com/show/16881/a-deep-dive-into-intels-alder-lake-microarchitectures},
	author = {Frumusanu, Andrei, Dr Ian Cutress},
	month = aug,
	year = {2021},
}

@book{barroso_datacenter_2013,
	title = {The {Datacenter} as a {Computer}: {An} {Introduction} to the {Design} of {Warehouse}-{Scale} {Machines}, {Second} edition},
	shorttitle = {The {Datacenter} as a {Computer}},
	url = {https://www.morganclaypool.com/doi/abs/10.2200/S00516ED2V01Y201306CAC024},
	publisher = {Morgan \& Claypool Publishers, San Rafael, California},
	author = {Barroso, Luiz André and Clidaras, Jimmy and Hölzle, Urs},
	month = jul,
	year = {2013},
	keywords = {key},
}

@misc{noauthor_ssh_nodate,
	title = {{SSH} protocol is the standard for strong authentication, secure connection, and encrypted file transfers. {We} developed it.},
	url = {https://www.ssh.com/academy/ssh/protocol},
	abstract = {SSH protocol is the standard for strong authentication, secure connection, and encrypted file transfers.  We developed it.},
	language = {en},
	urldate = {2022-07-19},
}

@inproceedings{vougioukas_brb_2019,
	title = {{BRB}: {Mitigating} {Branch} {Predictor} {Side}-{Channels}},
	shorttitle = {{BRB}},
	doi = {10.1109/HPCA.2019.00058},
	abstract = {Modern processors use branch prediction as an optimization to improve processor performance. Predictors have become larger and increasingly more sophisticated in order to achieve higher accuracies which are needed in high performance cores. However, branch prediction can also be a source of side channel exploits, as one context can deliberately change the branch predictor state and alter the instruction flow of another context. Current mitigation techniques either sacrifice performance for security, or fail to guarantee isolation when retaining the accuracy. Achieving both has proven to be challenging. In this work we address this by, (1) introducing the notions of steady-state and transient branch predictor accuracy, and (2) showing that current predictors increase their misprediction rate by as much as 90\% on average when forced to flush branch prediction state to remain secure. To solve this, (3) we introduce the branch retention buffer, a novel mechanism that partitions only the most useful branch predictor components to isolate separate contexts. Our mechanism makes thread isolation practical, as it stops the predictor from executing cold with little if any added area and no warm-up overheads. At the same time our results show that, compared to the state-of-the-art, average misprediction rates are reduced by 15-20\% without increasing area, leading to a 2\% performance increase.},
	booktitle = {2019 {IEEE} {International} {Symposium} on {High} {Performance} {Computer} {Architecture} ({HPCA})},
	author = {Vougioukas, Ilias and Nikoleris, Nikos and Sandberg, Andreas and Diestelhorst, Stephan and Al-Hashimi, Bashir M. and Merrett, Geoff V.},
	month = feb,
	year = {2019},
	note = {ISSN: 2378-203X},
	keywords = {Branch prediction, Branch retention buffer, Context, History, Perceptron, Program processors, Security, Steady-state, Switches, TAGE, Transient analysis, context switching, microarchitecture},
	pages = {466--477},
}

@article{evtyushkin_branchscope_2018,
	title = {{BranchScope}: {A} {New} {Side}-{Channel} {Attack} on {Directional} {Branch} {Predictor}},
	volume = {53},
	issn = {0362-1340},
	shorttitle = {{BranchScope}},
	url = {https://doi.org/10.1145/3296957.3173204},
	doi = {10.1145/3296957.3173204},
	abstract = {We present BranchScope - a new side-channel attack where the attacker infers the direction of an arbitrary conditional branch instruction in a victim program by manipulating the shared directional branch predictor. The directional component of the branch predictor stores the prediction on a given branch (taken or not-taken) and is a different component from the branch target buffer (BTB) attacked by previous work. BranchScope is the first fine-grained attack on the directional branch predictor, expanding our understanding of the side channel vulnerability of the branch prediction unit. Our attack targets complex hybrid branch predictors with unknown organization. We demonstrate how an attacker can force these predictors to switch to a simple 1-level mode to simplify the direction recovery. We carry out BranchScope on several recent Intel CPUs and also demonstrate the attack against an SGX enclave.},
	number = {2},
	urldate = {2022-07-16},
	journal = {ACM SIGPLAN Notices},
	author = {Evtyushkin, Dmitry and Riley, Ryan and Abu-Ghazaleh, Nael CSE {and} ECE and Ponomarev, Dmitry},
	month = mar,
	year = {2018},
	keywords = {SGX, attack, branch predictor, microarchitecture security, performance counters, side-channel, timing attacks},
	pages = {693--707},
}

@article{benila_plan_2022,
	title = {Plan and development of efficient branch predictor for in-order {RISC}-{V} processor},
	volume = {2393},
	issn = {0094-243X},
	url = {https://aip.scitation.org/doi/abs/10.1063/5.0074195},
	doi = {10.1063/5.0074195},
	number = {1},
	urldate = {2022-07-16},
	journal = {AIP Conference Proceedings},
	author = {Benila, A. and Priyadharshini, R. Indra and Slacer, Priscilla Packia and Jacob, J. Joyce and Theresa, M. Mercy},
	month = may,
	year = {2022},
	note = {Publisher: American Institute of Physics},
	pages = {020123},
}

@article{jecrc_university_jaipur_rajasthan_303905_india_two-level_2017,
	title = {Two-{Level} {Alloyed} {Branch} {Predictor} based on {Genetic} {Algorithm} for {Deep} {Pipelining} {Processors}},
	volume = {9},
	issn = {20750161, 2075017X},
	url = {http://www.mecs-press.org/ijmecs/ijmecs-v9-n5/v9n5-4.html},
	doi = {10.5815/ijmecs.2017.05.04},
	abstract = {To gain improved performance in multiple issue superscalar processors, the increment in instruction fetch and issue rate is pretty necessary. Evasion of control hazard is a primary source to get peak instruction level parallelism in superscalar processors. Conditional branch prediction can help in improving the performance of processors only when these predictors are equipped with algorithms to give higher accuracy. The Increment in single miss-prediction rate can cause wastage of more than 20\% of the instructions cycles, which leads us to an exploration of new techniques and algorithms that increase the accuracy of branch prediction. Alloying is a way to exploit the local and global history of different predictors in the same structure and sometimes also called hybrid branch prediction. In this paper, we aim to design a more accurate and robust two-level alloyed predictor, whose behavior is more dynamic on changing branch direction.},
	language = {en},
	number = {5},
	urldate = {2022-07-16},
	journal = {International Journal of Modern Education and Computer Science},
	author = {{JECRC University, Jaipur, Rajasthan 303905, India} and Goyal, Shivam and Singh, Jaskirat},
	month = may,
	year = {2017},
	pages = {27--33},
}

@inproceedings{schoeberl_time-predictable_2019,
	address = {New York, NY, USA},
	series = {{SAC} '19},
	title = {A time-predictable branch predictor},
	isbn = {978-1-4503-5933-7},
	url = {https://doi.org/10.1145/3297280.3297337},
	doi = {10.1145/3297280.3297337},
	abstract = {Long pipelines need good branch predictors to keep the pipeline running. Current branch predictors are optimized for the average case, which might not be a good fit for real-time systems and worst-case execution time analysis. This paper presents a time-predictable branch predictor co-designed with the associated worst-case execution time analysis. The branch predictor uses a fully-associative cache to track branch outcomes and destination addresses. The fully-associative cache avoids any false sharing of entries between branches. Therefore, we can analyze program scopes that contain a number of branches lower than or equal to the number of branches in the prediction table. Experimental results show that the worst-case execution time bounds of programs using the proposed predictor are lower than using static branch predictors at a moderate hardware cost.},
	urldate = {2022-07-15},
	booktitle = {Proceedings of the 34th {ACM}/{SIGAPP} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Schoeberl, Martin and Rouxel, Benjamin and Puaut, Isabelle},
	month = apr,
	year = {2019},
	keywords = {real-time systems, worst-case execution time},
	pages = {607--616},
}

@inproceedings{jimenez_dynamic_2001,
	title = {Dynamic branch prediction with perceptrons},
	doi = {10.1109/HPCA.2001.903263},
	abstract = {This paper presents a new method for branch prediction. The key idea is to use one of the simplest possible neural networks, the perceptron, as an alternative to the commonly used two-bit counters. Our predictor achieves increased accuracy by making use of long branch histories, which are possible becasue the hardware resources for our method scale linearly with the history length. By contrast, other purely dynamic schemes require exponential resources. We describe our design and evaluate it with respect to two well known predictors. We show that for a 4K byte hardware budget our method improves misprediction rates for the SPEC 2000 benchmarks by 10.1\% over the gshare predictor. Our experiments also provide a better understanding of the situations in which traditional predictors do and do not perform well. Finally, we describe techniques that allow our complex predictor to operate in one cycle.},
	booktitle = {Proceedings {HPCA} {Seventh} {International} {Symposium} on {High}-{Performance} {Computer} {Architecture}},
	author = {Jimenez, D.A. and Lin, C.},
	month = jan,
	year = {2001},
	note = {ISSN: 1530-0897},
	keywords = {Accuracy, Computer architecture, Counting circuits, Hardware, History, Modems, Neural networks, Parallel processing, Prefetching, Space exploration},
	pages = {197--206},
}

@inproceedings{zhou_simplebp_2017,
	title = {{SimpleBP}: {A} {Lightweight} {Branch} {Prediction} {Simulator} for {Effective} {Design} {Exploration}},
	shorttitle = {{SimpleBP}},
	doi = {10.1109/NAS.2017.8026877},
	abstract = {Besides the accuracy of prediction, chip area occupancy and power consumption also should be taken into account in the design of branch predictors. Many of the previous prediction simulation platforms have either only considered accuracy computed with coarse-grained updating model, or just been the low-speed full system simulators. In this paper, We presents SimpleBP, a lightweight prediction simulator based on trace driven. It leverages the SystemC language to simulate branch predictor at clock cycle granularity. And the CACTI model is introduced to evaluate area and power consumption. The experiment results show that SimpleBP can accurately give multiple evaluations of branch predictors.},
	booktitle = {2017 {International} {Conference} on {Networking}, {Architecture}, and {Storage} ({NAS})},
	author = {Zhou, Chaobing and Huang, Libo and Li, Zhisheng and Dou, Qiang},
	month = aug,
	year = {2017},
	keywords = {Clocks, Computational modeling, Hardware, Pipelines, Power demand, Predictive models, Random access memory},
	pages = {1--2},
}

@inproceedings{evers_analysis_1998,
	address = {USA},
	series = {{ISCA} '98},
	title = {An analysis of correlation and predictability: what makes two-level branch predictors work},
	isbn = {978-0-8186-8491-3},
	shorttitle = {An analysis of correlation and predictability},
	url = {https://doi.org/10.1145/279358.279368},
	doi = {10.1145/279358.279368},
	abstract = {Pipeline flushes due to branch mispredictions is one of the most serious problems facing the designer of a deeply pipelined, superscalar processor. Many branch predictors have been proposed to help alleviate this problem, including two-level adaptive branch predictors and hybrid branch predictors.Numerous studies have shown which predictors and configurations best predict the branches in a given set of benchmarks. Some studies have also investigated effects, such as pattern history table interference, that can be detrimental to the performance of these predictors. However, little research has been done on which characteristics of branch behavior make predictors perform well.In this paper, we investigate and quantify reasons why branches are predictable. We show that some of this predictability is not captured by the two-level adaptive branch predictors. An understanding of the predictability of branches may lead to insights ultimately resulting in better or less complex predictors. We also investigate and quantify what fraction of the branches in each benchmark is predictable using each of the methods described in this paper.},
	urldate = {2022-07-12},
	booktitle = {Proceedings of the 25th annual international symposium on {Computer} architecture},
	publisher = {IEEE Computer Society},
	author = {Evers, Marius and Patel, Sanjay J. and Chappell, Robert S. and Patt, Yale N.},
	month = apr,
	year = {1998},
	pages = {52--61},
}

@article{cleary_data_1984,
	title = {Data {Compression} {Using} {Adaptive} {Coding} and {Partial} {String} {Matching}},
	volume = {32},
	issn = {1558-0857},
	doi = {10.1109/TCOM.1984.1096090},
	abstract = {The recently developed technique of arithmetic coding, in conjunction with a Markov model of the source, is a powerful method of data compression in situations where a linear treatment is inappropriate. Adaptive coding allows the model to be constructed dynamically by both encoder and decoder during the course of the transmission, and has been shown to incur a smaller coding overhead than explicit transmission of the model's statistics. But there is a basic conflict between the desire to use high-order Markov models and the need to have them formed quickly as the initial part of the message is sent. This paper describes how the conflict can be resolved with partial string matching, and reports experimental results which show that mixed-case English text can be coded in as little as 2.2 bits/ character with no prior knowledge of the source.},
	number = {4},
	journal = {IEEE Transactions on Communications},
	author = {Cleary, J. and Witten, I.},
	month = apr,
	year = {1984},
	note = {Conference Name: IEEE Transactions on Communications},
	keywords = {Adaptive coding, Arithmetic, Data communication, Data compression, Decoding, Dictionaries, Entropy, Frequency, Huffman coding, Statistics},
	pages = {396--402},
}
